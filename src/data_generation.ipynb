{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_experimental.tabular_synthetic_data.openai import (\n",
    "    OPENAI_TEMPLATE,\n",
    "    create_openai_data_generator,\n",
    ")\n",
    "from langchain_experimental.tabular_synthetic_data.prompts import (\n",
    "    SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "    SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Your Data Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalBilling(BaseModel):\n",
    "    patient_id: int\n",
    "    patient_name: str\n",
    "    diagnosis_code: str\n",
    "    procedure_code: str\n",
    "    total_charge: float\n",
    "    insurance_claim_amount: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 123456, Patient Name: John Doe, Diagnosis Code: \n",
    "        J20.9, Procedure Code: 99203, Total Charge: $500, Insurance Claim Amount: $350\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 789012, Patient Name: Johnson Smith, Diagnosis \n",
    "        Code: M54.5, Procedure Code: 99213, Total Charge: $150, Insurance Claim Amount: $120\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 345678, Patient Name: Emily Stone, Diagnosis Code: \n",
    "        E11.9, Procedure Code: 99214, Total Charge: $300, Insurance Claim Amount: $250\"\"\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Craft a Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_TEMPLATE = PromptTemplate(input_variables=[\"example\"], template=\"{example}\")\n",
    "\n",
    "prompt_template = FewShotPromptTemplate(\n",
    "    prefix=SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "    examples=examples,\n",
    "    suffix=SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    "    input_variables=[\"subject\", \"extra\"],\n",
    "    example_prompt=OPENAI_TEMPLATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating the Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_generator = create_openai_data_generator(\n",
    "    output_schema=MedicalBilling,\n",
    "    llm=ChatOpenAI(\n",
    "        temperature=1\n",
    "    ),  # You'll need to replace with your actual Language Model instance\n",
    "    prompt=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[MedicalBilling(patient_id=987654, patient_name='Sophia Hernandez', diagnosis_code='D50.0', procedure_code='99204', total_charge=400.0, insurance_claim_amount=300.0),\n",
       " MedicalBilling(patient_id=123456, patient_name='Lucas Thompson', diagnosis_code='R07.9', procedure_code='99203', total_charge=250.0, insurance_claim_amount=200.0),\n",
       " MedicalBilling(patient_id=987654, patient_name='Amelia Patel', diagnosis_code='I10', procedure_code='99215', total_charge=350.0, insurance_claim_amount=275.0),\n",
       " MedicalBilling(patient_id=987654, patient_name='Harper Wilson', diagnosis_code='E11.9', procedure_code='99214', total_charge=300.0, insurance_claim_amount=250.0),\n",
       " MedicalBilling(patient_id=123457, patient_name='Ezekiel Rodriguez', diagnosis_code='C45.0', procedure_code='99204', total_charge=275.0, insurance_claim_amount=225.0),\n",
       " MedicalBilling(patient_id=987653, patient_name='Juniper Singh', diagnosis_code='C20', procedure_code='99213', total_charge=320.0, insurance_claim_amount=260.0),\n",
       " MedicalBilling(patient_id=456789, patient_name='Zephyr Chang', diagnosis_code='I50.9', procedure_code='99203', total_charge=285.0, insurance_claim_amount=235.0),\n",
       " MedicalBilling(patient_id=987123, patient_name='Octavia Patel', diagnosis_code='I20.0', procedure_code='99214', total_charge=300.0, insurance_claim_amount=240.0),\n",
       " MedicalBilling(patient_id=123456, patient_name='Xander Williams', diagnosis_code='M54.5', procedure_code='99204', total_charge=350.0, insurance_claim_amount=290.0),\n",
       " MedicalBilling(patient_id=654321, patient_name='Aurelia Montoya', diagnosis_code='S72.00', procedure_code='99213', total_charge=275.0, insurance_claim_amount=225.0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_results = synthetic_data_generator.generate(\n",
    "    subject=\"medical_billing\",\n",
    "    extra=\"the name must be chosen at random. Make it something you wouldn't normally choose.\",\n",
    "    runs=10,\n",
    ")\n",
    "\n",
    "\n",
    "synthetic_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fields': ['blue', 'yellow'],\n",
       " 'preferences': {},\n",
       " 'text': 'The vibrant blue sky contrasted beautifully with the golden yellow sunflower fields, creating a stunning display of natural beauty.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_experimental.synthetic_data import (\n",
    "    DatasetGenerator,\n",
    "    create_data_generation_chain,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "chain = create_data_generation_chain(model)\n",
    "\n",
    "\n",
    "chain({\"fields\": [\"blue\", \"yellow\"], \"preferences\": {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': {'colors': ['blue', 'yellow']},\n",
       " 'preferences': {'style': 'Make it in a style of a weather forecast.'},\n",
       " 'text': \"In today's weather forecast, expect a vibrant display of colors in shades of blue and yellow, creating a stunning contrast against the clear blue skies and golden sunshine.\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\n",
    "    {\n",
    "        \"fields\": {\"colors\": [\"blue\", \"yellow\"]},\n",
    "        \"preferences\": {\"style\": \"Make it in a style of a weather forecast.\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': {'actor': 'Tom Hanks', 'movies': ['Forrest Gump', 'Green Mile']},\n",
       " 'preferences': None,\n",
       " 'text': 'Tom Hanks, known for his versatile acting skills, has starred in iconic films such as \"Forrest Gump\" and \"Green Mile,\" showcasing his ability to portray a wide range of characters with depth and emotion.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\n",
    "    {\n",
    "        \"fields\": {\"actor\": \"Tom Hanks\", \"movies\": [\"Forrest Gump\", \"Green Mile\"]},\n",
    "        \"preferences\": None,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': [{'actor': 'Tom Hanks', 'movies': ['Forrest Gump', 'Green Mile']},\n",
       "  {'actor': 'Mads Mikkelsen', 'movies': ['Hannibal', 'Another round']}],\n",
       " 'preferences': {'minimum_length': 200, 'style': 'gossip'},\n",
       " 'text': 'Tom Hanks, known for his iconic roles in movies like \"Forrest Gump\" and \"Green Mile\", has captivated audiences with his unparalleled talent and charm, while Mads Mikkelsen, famous for his chilling performances in \"Hannibal\" and \"Another round\", has established himself as a versatile and mesmerizing actor in the world of cinema.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\n",
    "    {\n",
    "        \"fields\": [\n",
    "            {\"actor\": \"Tom Hanks\", \"movies\": [\"Forrest Gump\", \"Green Mile\"]},\n",
    "            {\"actor\": \"Mads Mikkelsen\", \"movies\": [\"Hannibal\", \"Another round\"]},\n",
    "        ],\n",
    "        \"preferences\": {\"minimum_length\": 200, \"style\": \"gossip\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating exemplary dataset for extraction benchmarking purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fields': {'Actor': 'Tom Hanks',\n",
       "   'Film': ['Forrest Gump',\n",
       "    'Saving Private Ryan',\n",
       "    'The Green Mile',\n",
       "    'Toy Story',\n",
       "    'Catch Me If You Can']},\n",
       "  'preferences': {'style': 'informal', 'minimal length': 500},\n",
       "  'text': 'Tom Hanks, known for his iconic roles in films such as Forrest Gump, Saving Private Ryan, The Green Mile, Toy Story, and Catch Me If You Can, is a versatile actor who effortlessly brings depth and charm to every character he portrays on screen.'},\n",
       " {'fields': {'Actor': 'Tom Hardy',\n",
       "   'Film': ['Inception',\n",
       "    'The Dark Knight Rises',\n",
       "    'Mad Max: Fury Road',\n",
       "    'The Revenant',\n",
       "    'Dunkirk']},\n",
       "  'preferences': {'style': 'informal', 'minimal length': 500},\n",
       "  'text': 'Tom Hardy, known for his versatile roles in films such as \"Inception,\" \"The Dark Knight Rises,\" \"Mad Max: Fury Road,\" \"The Revenant,\" and \"Dunkirk,\" has proven time and time again that he is a powerhouse in the world of acting, captivating audiences with his intense performances and ability to completely embody each character he takes on.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = [\n",
    "    {\n",
    "        \"Actor\": \"Tom Hanks\",\n",
    "        \"Film\": [\n",
    "            \"Forrest Gump\",\n",
    "            \"Saving Private Ryan\",\n",
    "            \"The Green Mile\",\n",
    "            \"Toy Story\",\n",
    "            \"Catch Me If You Can\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"Actor\": \"Tom Hardy\",\n",
    "        \"Film\": [\n",
    "            \"Inception\",\n",
    "            \"The Dark Knight Rises\",\n",
    "            \"Mad Max: Fury Road\",\n",
    "            \"The Revenant\",\n",
    "            \"Dunkirk\",\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "generator = DatasetGenerator(model, {\"style\": \"informal\", \"minimal length\": 500})\n",
    "dataset = generator(inp)\n",
    "\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction from generated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Actor(Actor='Tom Hanks', Film=['Forrest Gump', 'Saving Private Ryan', 'The Green Mile', 'Toy Story', 'Catch Me If You Can'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import pydantic\n",
    "\n",
    "\n",
    "class Config:\n",
    "    arbitrary_types_allowed = True\n",
    "\n",
    "@pydantic.dataclasses.dataclass(config=Config)\n",
    "class Actor(BaseModel):\n",
    "    Actor: str = Field(description=\"name of an actor\")\n",
    "    Film: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "\n",
    "\n",
    "llm = OpenAI()\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Extract fields from a given text.\\n{format_instructions}\\n{text}\\n\",\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(text=dataset[0][\"text\"])\n",
    "output = llm(_input.to_string())\n",
    "\n",
    "parsed = parser.parse(output)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(parsed.Actor == inp[0][\"Actor\"]) & (parsed.Film == inp[0][\"Film\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = create_extraction_chain_pydantic(pydantic_schema=Actor, llm=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = extractor.run(dataset[1][\"text\"])\n",
    "extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tom Hardy, known for his versatile roles in films such as \"Inception,\" \"The Dark Knight Rises,\" \"Mad Max: Fury Road,\" \"The Revenant,\" and \"Dunkirk,\" has proven time and time again that he is a powerhouse in the world of acting, captivating audiences with his intense performances and ability to completely embody each character he takes on.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][\"text\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
