{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Query Analysis System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --quiet youtube-transcript-api pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OpenGPTs',\n",
       " 'Building a web RAG chatbot: using LangChain, Exa (prev. Metaphor), LangSmith, and Hosted Langserve',\n",
       " 'Streaming Events: Introducing a new `stream_events` method',\n",
       " 'LangGraph: Multi-Agent Workflows',\n",
       " 'Build and Deploy a RAG app with Pinecone Serverless',\n",
       " 'Auto-Prompt Builder (with Hosted LangServe)',\n",
       " 'Build a Full Stack RAG App With TypeScript',\n",
       " 'Getting Started with Multi-Modal LLMs',\n",
       " 'SQL Research Assistant',\n",
       " 'Skeleton-of-Thought: Building a New Template from Scratch',\n",
       " 'Benchmarking RAG over LangChain Docs',\n",
       " 'Building a Research Assistant from Scratch',\n",
       " 'LangServe and LangChain Templates Webinar']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "urls = [\n",
    "    \"https://www.youtube.com/watch?v=HAn9vnJy6S4\",\n",
    "    \"https://www.youtube.com/watch?v=dA1cHGACXCo\",\n",
    "    \"https://www.youtube.com/watch?v=ZcEMLz27sL4\",\n",
    "    \"https://www.youtube.com/watch?v=hvAPnpSfSGo\",\n",
    "    \"https://www.youtube.com/watch?v=EhlPDL4QrWY\",\n",
    "    \"https://www.youtube.com/watch?v=mmBo8nlu2j0\",\n",
    "    \"https://www.youtube.com/watch?v=rQdibOsL1ps\",\n",
    "    \"https://www.youtube.com/watch?v=28lC4fqukoc\",\n",
    "    \"https://www.youtube.com/watch?v=es-9MgxB-uc\",\n",
    "    \"https://www.youtube.com/watch?v=wLRHwKuKvOE\",\n",
    "    \"https://www.youtube.com/watch?v=ObIltMaRJvY\",\n",
    "    \"https://www.youtube.com/watch?v=DjuXACWYkkU\",\n",
    "    \"https://www.youtube.com/watch?v=o7C9ld6Ln-M\",\n",
    "]\n",
    "docs = []\n",
    "for url in urls:\n",
    "    docs.extend(YoutubeLoader.from_youtube_url(url, add_video_info=True).load())\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "# Add some additional metadata: what year the video was published\n",
    "for doc in docs:\n",
    "    doc.metadata[\"publish_year\"] = int(\n",
    "        datetime.datetime.strptime(\n",
    "            doc.metadata[\"publish_date\"], \"%Y-%m-%d %H:%M:%S\"\n",
    "        ).strftime(\"%Y\")\n",
    "    )\n",
    "\n",
    "\n",
    "[doc.metadata[\"title\"] for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'HAn9vnJy6S4',\n",
       " 'title': 'OpenGPTs',\n",
       " 'description': 'Unknown',\n",
       " 'view_count': 8948,\n",
       " 'thumbnail_url': 'https://i.ytimg.com/vi/HAn9vnJy6S4/hq720.jpg',\n",
       " 'publish_date': '2024-01-31 00:00:00',\n",
       " 'length': 1530,\n",
       " 'author': 'LangChain',\n",
       " 'publish_year': 2024}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hello today I want to talk about open gpts open gpts is a project that we built here at linkchain uh that replicates the GPT store in a few ways so it creates uh end user-facing friendly interface to create different Bots and these Bots can have access to different tools and they can uh be given files to retrieve things over and basically it's a way to create a variety of bots and expose the configuration of these Bots to end users it's all open source um it can be used with open AI it can be us\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "chunked_docs = text_splitter.split_documents(docs)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    chunked_docs,\n",
    "    embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval without query analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenGPTs\n",
      "hardcoded that it will always do a retrieval step here the assistant decides whether to do a retrieval step or not sometimes this is good sometimes this is bad sometimes it you don't need to do a retrieval step when I said hi it didn't need to call it tool um but other times you know the the llm might mess up and not realize that it needs to do a retrieval step and so the rag bot will always do a retrieval step so it's more focused there because this is also a simpler architecture so it's always\n"
     ]
    }
   ],
   "source": [
    "search_results = vectorstore.similarity_search(\"how do I build a RAG agent\")\n",
    "print(search_results[0].metadata[\"title\"])\n",
    "print(search_results[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build and Deploy a RAG app with Pinecone Serverless\n",
      "2024-01-16 00:00:00\n",
      "sure what's going on of course this data sets from a third party provider we didn't actually make it ourselves um so there's possible that there's some irregularities in the data itself um but let's go back we ran our chain we can see our answer you know it looks sane we can check our chain here so again here's the retrieve chunks from from our serverless index we can go look here and they're all plumbed into our prompt so that's pretty cool and here's our answer now I noted that the retriev chu\n"
     ]
    }
   ],
   "source": [
    "search_results = vectorstore.similarity_search(\"videos on RAG published in 2023\")\n",
    "print(search_results[0].metadata[\"title\"])\n",
    "print(search_results[0].metadata[\"publish_date\"])\n",
    "print(search_results[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class Search(BaseModel):\n",
    "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
    "\n",
    "    query: str = Field(\n",
    "        ...,\n",
    "        description=\"Similarity search query applied to video transcripts.\",\n",
    "    )\n",
    "    publish_year: Optional[int] = Field(None, description=\"Year video was published\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Search(query='build RAG agent', publish_year=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
    "Given a question, return a list of database queries optimized to retrieve the most relevant results.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(Search)\n",
    "query_analyzer = {\"question\": RunnablePassthrough()} | prompt | structured_llm\n",
    "\n",
    "\n",
    "query_analyzer.invoke(\"how do I build a RAG agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Search(query='RAG', publish_year=2023)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\"videos on RAG published in 2023\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval with query analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Getting Started with Multi-Modal LLMs', '2023-12-20 00:00:00'),\n",
       " ('Getting Started with Multi-Modal LLMs', '2023-12-20 00:00:00'),\n",
       " ('Getting Started with Multi-Modal LLMs', '2023-12-20 00:00:00'),\n",
       " ('LangServe and LangChain Templates Webinar', '2023-11-02 00:00:00')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def retrieval(search: Search) -> List[Document]:\n",
    "    if search.publish_year is not None:\n",
    "        # This is syntax specific to Chroma,\n",
    "        # the vector database we are using.\n",
    "        _filter = {\"publish_year\": {\"$eq\": search.publish_year}}\n",
    "    else:\n",
    "        _filter = None\n",
    "    return vectorstore.similarity_search(search.query, filter=_filter)\n",
    "\n",
    "\n",
    "retrieval_chain = query_analyzer | retrieval\n",
    "\n",
    "\n",
    "results = retrieval_chain.invoke(\"RAG tutorial published in 2023\")\n",
    "\n",
    "\n",
    "[(doc.metadata[\"title\"], doc.metadata[\"publish_date\"]) for doc in results]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
