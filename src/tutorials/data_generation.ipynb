{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1302a608-4b4d-46bf-bd0c-b4f13eff2e5e",
   "metadata": {},
   "source": [
    "---\n",
    "sidebar_class_name: hidden\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3571cc",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain/blob/master/docs/docs/use_cases/data_generation.ipynb)\n",
    "\n",
    "# Generate Synthetic Data\n",
    "\n",
    "Synthetic data is artificially generated data, rather than data collected from real-world events. It's used to simulate real data without compromising privacy or encountering real-world limitations. \n",
    "\n",
    "Benefits of Synthetic Data:\n",
    "\n",
    "1. **Privacy and Security**: No real personal data at risk of breaches.\n",
    "2. **Data Augmentation**: Expands datasets for machine learning.\n",
    "3. **Flexibility**: Create specific or rare scenarios.\n",
    "4. **Cost-effective**: Often cheaper than real-world data collection.\n",
    "5. **Regulatory Compliance**: Helps navigate strict data protection laws.\n",
    "6. **Model Robustness**: Can lead to better generalizing AI models.\n",
    "7. **Rapid Prototyping**: Enables quick testing without real data.\n",
    "8. **Controlled Experimentation**: Simulate specific conditions.\n",
    "9. **Access to Data**: Alternative when real data isn't available.\n",
    "\n",
    "Note: Despite the benefits, synthetic data should be used carefully, as it may not always capture real-world complexities.\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "In this notebook, we'll dive deep into generating synthetic medical billing records using the langchain library. This tool is particularly useful when you want to develop or test algorithms but don't want to use real patient data due to privacy concerns or data availability issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca57012",
   "metadata": {},
   "source": [
    "### Setup\n",
    "First, you'll need to have the langchain library installed, along with its dependencies. Since we're using the OpenAI generator chain, we'll install that as well. Since this is an experimental lib, we'll need to include `langchain_experimental` in our installs. We'll then import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0377478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain_experimental langchain-openai\n",
    "# Set env var OPENAI_API_KEY or load from a .env file:\n",
    "# import dotenv\n",
    "# dotenv.load_dotenv()\n",
    "\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "from langchain_experimental.tabular_synthetic_data.openai import (\n",
    "    OPENAI_TEMPLATE,\n",
    "    create_openai_data_generator,\n",
    ")\n",
    "from langchain_experimental.tabular_synthetic_data.prompts import (\n",
    "    SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "    SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a0917b",
   "metadata": {},
   "source": [
    "## 1. Define Your Data Model\n",
    "Every dataset has a structure or a \"schema\". The MedicalBilling class below serves as our schema for the synthetic data. By defining this, we're informing our synthetic data generator about the shape and nature of data we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291bad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalBilling(BaseModel):\n",
    "    patient_id: int\n",
    "    patient_name: str\n",
    "    diagnosis_code: str\n",
    "    procedure_code: str\n",
    "    total_charge: float\n",
    "    insurance_claim_amount: float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2059ca63",
   "metadata": {},
   "source": [
    "For instance, every record will have a `patient_id` that's an integer, a `patient_name` that's a string, and so on.\n",
    "\n",
    "## 2. Sample Data\n",
    "To guide the synthetic data generator, it's useful to provide it with a few real-world-like examples. These examples serve as a \"seed\" - they're representative of the kind of data you want, and the generator will use them to create more data that looks similar.\n",
    "\n",
    "Here are some fictional medical billing records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b989b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 123456, Patient Name: John Doe, Diagnosis Code: \n",
    "        J20.9, Procedure Code: 99203, Total Charge: $500, Insurance Claim Amount: $350\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 789012, Patient Name: Johnson Smith, Diagnosis \n",
    "        Code: M54.5, Procedure Code: 99213, Total Charge: $150, Insurance Claim Amount: $120\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"example\": \"\"\"Patient ID: 345678, Patient Name: Emily Stone, Diagnosis Code: \n",
    "        E11.9, Procedure Code: 99214, Total Charge: $300, Insurance Claim Amount: $250\"\"\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e28809",
   "metadata": {},
   "source": [
    "## 3. Craft a Prompt Template\n",
    "The generator doesn't magically know how to create our data; we need to guide it. We do this by creating a prompt template. This template helps instruct the underlying language model on how to produce synthetic data in the desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6e042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_TEMPLATE = PromptTemplate(input_variables=[\"example\"], template=\"{example}\")\n",
    "\n",
    "prompt_template = FewShotPromptTemplate(\n",
    "    prefix=SYNTHETIC_FEW_SHOT_PREFIX,\n",
    "    examples=examples,\n",
    "    suffix=SYNTHETIC_FEW_SHOT_SUFFIX,\n",
    "    input_variables=[\"subject\", \"extra\"],\n",
    "    example_prompt=OPENAI_TEMPLATE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6da3cb",
   "metadata": {},
   "source": [
    "The `FewShotPromptTemplate` includes:\n",
    "\n",
    "- `prefix` and `suffix`: These likely contain guiding context or instructions.\n",
    "- `examples`: The sample data we defined earlier.\n",
    "- `input_variables`: These variables (\"subject\", \"extra\") are placeholders you can dynamically fill later. For instance, \"subject\" might be filled with \"medical_billing\" to guide the model further.\n",
    "- `example_prompt`: This prompt template is the format we want each example row to take in our prompt.\n",
    "\n",
    "## 4. Creating the Data Generator\n",
    "With the schema and the prompt ready, the next step is to create the data generator. This object knows how to communicate with the underlying language model to get synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9ba911",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data_generator = create_openai_data_generator(\n",
    "    output_schema=MedicalBilling,\n",
    "    llm=ChatOpenAI(\n",
    "        temperature=1\n",
    "    ),  # You'll need to replace with your actual Language Model instance\n",
    "    prompt=prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4198bd6",
   "metadata": {},
   "source": [
    "## 5. Generate Synthetic Data\n",
    "Finally, let's get our synthetic data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a424c890",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_results = synthetic_data_generator.generate(\n",
    "    subject=\"medical_billing\",\n",
    "    extra=\"the name must be chosen at random. Make it something you wouldn't normally choose.\",\n",
    "    runs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4402e9",
   "metadata": {},
   "source": [
    "This command asks the generator to produce 10 synthetic medical billing records. The results are stored in `synthetic_results`. The output will be a list of the MedicalBilling pydantic models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4cbf9",
   "metadata": {},
   "source": [
    "### Other implementations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e715d94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.synthetic_data import (\n",
    "    DatasetGenerator,\n",
    "    create_data_generation_chain,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94fccedd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "chain = create_data_generation_chain(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4314c3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fields': ['blue', 'yellow'],\n",
       " 'preferences': {},\n",
       " 'text': \"The vibrant blue sky contrasted beautifully with the bright yellow sunflowers, creating a stunning display of nature's colors.\"}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"fields\": [\"blue\", \"yellow\"], \"preferences\": {}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b116c487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': {'colors': ['blue', 'yellow']},\n",
       " 'preferences': {'style': 'Make it in a style of a weather forecast.'},\n",
       " 'text': \"In today's weather forecast, expect a vibrant display of colors with a mix of blue skies and yellow sunshine, creating a picturesque scene that will surely brighten up your day.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\n",
    "    {\n",
    "        \"fields\": {\"colors\": [\"blue\", \"yellow\"]},\n",
    "        \"preferences\": {\"style\": \"Make it in a style of a weather forecast.\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff823394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': {'actor': 'Tom Hanks', 'movies': ['Forrest Gump', 'Green Mile']},\n",
       " 'preferences': None,\n",
       " 'text': 'Tom Hanks, known for his iconic roles in movies such as \"Forrest Gump\" and \"Green Mile,\" has captivated audiences worldwide with his exceptional talent and versatility as an actor.'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\n",
    "    {\n",
    "        \"fields\": {\"actor\": \"Tom Hanks\", \"movies\": [\"Forrest Gump\", \"Green Mile\"]},\n",
    "        \"preferences\": None,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ea1ad5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': [{'actor': 'Tom Hanks', 'movies': ['Forrest Gump', 'Green Mile']},\n",
       "  {'actor': 'Mads Mikkelsen', 'movies': ['Hannibal', 'Another round']}],\n",
       " 'preferences': {'minimum_length': 200, 'style': 'gossip'},\n",
       " 'text': 'Rumor has it that Tom Hanks, known for his iconic roles in movies like Forrest Gump and Green Mile, is set to star alongside the talented Mads Mikkelsen, best known for his chilling performances in Hannibal and Another Round, in an upcoming blockbuster film that is sure to captivate audiences worldwide.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\n",
    "    {\n",
    "        \"fields\": [\n",
    "            {\"actor\": \"Tom Hanks\", \"movies\": [\"Forrest Gump\", \"Green Mile\"]},\n",
    "            {\"actor\": \"Mads Mikkelsen\", \"movies\": [\"Hannibal\", \"Another round\"]},\n",
    "        ],\n",
    "        \"preferences\": {\"minimum_length\": 200, \"style\": \"gossip\"},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c7a4bb",
   "metadata": {},
   "source": [
    "As we can see created examples are diversified and possess information we wanted them to have. Also, their style reflects the given preferences quite well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7f55a",
   "metadata": {},
   "source": [
    "## Generating exemplary dataset for extraction benchmarking purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94e98bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [\n",
    "    {\n",
    "        \"Actor\": \"Tom Hanks\",\n",
    "        \"Film\": [\n",
    "            \"Forrest Gump\",\n",
    "            \"Saving Private Ryan\",\n",
    "            \"The Green Mile\",\n",
    "            \"Toy Story\",\n",
    "            \"Catch Me If You Can\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"Actor\": \"Tom Hardy\",\n",
    "        \"Film\": [\n",
    "            \"Inception\",\n",
    "            \"The Dark Knight Rises\",\n",
    "            \"Mad Max: Fury Road\",\n",
    "            \"The Revenant\",\n",
    "            \"Dunkirk\",\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "generator = DatasetGenerator(model, {\"style\": \"informal\", \"minimal length\": 500})\n",
    "dataset = generator(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "478eaca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'fields': {'Actor': 'Tom Hanks',\n",
       "   'Film': ['Forrest Gump',\n",
       "    'Saving Private Ryan',\n",
       "    'The Green Mile',\n",
       "    'Toy Story',\n",
       "    'Catch Me If You Can']},\n",
       "  'preferences': {'style': 'informal', 'minimal length': 500},\n",
       "  'text': 'Tom Hanks, known for his iconic roles in films such as \"Forrest Gump,\" \"Saving Private Ryan,\" \"The Green Mile,\" \"Toy Story,\" and \"Catch Me If You Can,\" has solidified himself as a versatile and talented actor in Hollywood.'},\n",
       " {'fields': {'Actor': 'Tom Hardy',\n",
       "   'Film': ['Inception',\n",
       "    'The Dark Knight Rises',\n",
       "    'Mad Max: Fury Road',\n",
       "    'The Revenant',\n",
       "    'Dunkirk']},\n",
       "  'preferences': {'style': 'informal', 'minimal length': 500},\n",
       "  'text': 'Tom Hardy has showcased his versatility as an actor in a variety of acclaimed films, including \"Inception,\" \"The Dark Knight Rises,\" \"Mad Max: Fury Road,\" \"The Revenant,\" and \"Dunkirk,\" proving himself as a powerhouse in the industry with his ability to tackle complex characters across diverse genres.'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a7d64",
   "metadata": {},
   "source": [
    "## Extraction from generated examples\n",
    "Okay, let's see if we can now extract output from this generated data and how it compares with our case!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03c6a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9461d225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(BaseModel):\n",
    "    Actor: str = Field(description=\"name of an actor\")\n",
    "    Film: List[str] = Field(description=\"list of names of films they starred in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8390171d",
   "metadata": {},
   "source": [
    "### Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a5528d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Actor(Actor='Tom Hanks', Film=['Forrest Gump', 'Saving Private Ryan', 'The Green Mile', 'Toy Story', 'Catch Me If You Can'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = OpenAI()\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Extract fields from a given text.\\n{format_instructions}\\n{text}\\n\",\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "_input = prompt.format_prompt(text=dataset[0][\"text\"])\n",
    "output = llm(_input.to_string())\n",
    "\n",
    "parsed = parser.parse(output)\n",
    "parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "926a7eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(parsed.Actor == inp[0][\"Actor\"]) & (parsed.Film == inp[0][\"Film\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f0b87",
   "metadata": {},
   "source": [
    "### Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "523bb584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: LangChain has introduced a method called `with_structured_output` thatis available on ChatModels capable of tool calling.You can read more about the method here: <https://python.langchain.com/docs/modules/model_io/chat/structured_output/>. Please follow our extraction use case documentation for more guidelineson how to do information extraction with LLMs.<https://python.langchain.com/docs/use_cases/extraction/>. If you notice other issues, please provide feedback here:<https://github.com/langchain-ai/langchain/discussions/18154>\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "no validator found for <class '__main__.Actor'>, see `arbitrary_types_allowed` in Config",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m extractor \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_extraction_chain_pydantic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mActor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m extracted \u001b[38;5;241m=\u001b[39m extractor\u001b[38;5;241m.\u001b[39mrun(dataset[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      3\u001b[0m extracted\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:168\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     emit_warning()\n\u001b[0;32m--> 168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain/chains/openai_functions/extraction.py:172\u001b[0m, in \u001b[0;36mcreate_extraction_chain_pydantic\u001b[0;34m(pydantic_schema, llm, prompt, verbose)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\n\u001b[1;32m    118\u001b[0m     since\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.14\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    119\u001b[0m     message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m     verbose: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    157\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Chain:\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a chain that extracts information from a passage using pydantic schema.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m        Chain that can be used to extract information from a passage.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPydanticSchema\u001b[39;00m(BaseModel):\n\u001b[1;32m    173\u001b[0m         info: List[pydantic_schema]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     openai_schema \u001b[38;5;241m=\u001b[39m pydantic_schema\u001b[38;5;241m.\u001b[39mschema()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/main.py:197\u001b[0m, in \u001b[0;36mModelMetaclass.__new__\u001b[0;34m(mcs, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    190\u001b[0m         is_untouched(value)\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m ann_type \u001b[38;5;241m!=\u001b[39m PyObject\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m         )\n\u001b[1;32m    195\u001b[0m     ):\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m     fields[ann_name] \u001b[38;5;241m=\u001b[39m \u001b[43mModelField\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mannotation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mann_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ann_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m namespace \u001b[38;5;129;01mand\u001b[39;00m config\u001b[38;5;241m.\u001b[39munderscore_attrs_are_private:\n\u001b[1;32m    205\u001b[0m     private_attributes[ann_name] \u001b[38;5;241m=\u001b[39m PrivateAttr()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/fields.py:504\u001b[0m, in \u001b[0;36mModelField.infer\u001b[0;34m(cls, name, value, annotation, class_validators, config)\u001b[0m\n\u001b[1;32m    501\u001b[0m     required \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    502\u001b[0m annotation \u001b[38;5;241m=\u001b[39m get_annotation_from_field_info(annotation, field_info, name, config\u001b[38;5;241m.\u001b[39mvalidate_assignment)\n\u001b[0;32m--> 504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43malias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_validators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_factory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequired\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequired\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/fields.py:434\u001b[0m, in \u001b[0;36mModelField.__init__\u001b[0;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m SHAPE_SINGLETON\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mprepare_field(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/fields.py:550\u001b[0m, in \u001b[0;36mModelField.prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m ForwardRef \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m DeferredType:\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;66;03m# self.type_ is currently a ForwardRef and there's nothing we can do now,\u001b[39;00m\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;66;03m# user will need to call model.update_forward_refs()\u001b[39;00m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_type_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequired \u001b[38;5;129;01mis\u001b[39;00m Undefined:\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequired \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/fields.py:756\u001b[0m, in \u001b[0;36mModelField._type_analysis\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFields of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morigin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m are not supported.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    755\u001b[0m \u001b[38;5;66;03m# type_ has been refined eg. as the type of a List and sub_fields needs to be populated\u001b[39;00m\n\u001b[0;32m--> 756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_fields \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_sub_type\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/fields.py:806\u001b[0m, in \u001b[0;36mModelField._create_sub_type\u001b[0;34m(self, type_, name, for_keys)\u001b[0m\n\u001b[1;32m    791\u001b[0m     class_validators \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    792\u001b[0m         k: Validator(\n\u001b[1;32m    793\u001b[0m             func\u001b[38;5;241m=\u001b[39mv\u001b[38;5;241m.\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item\n\u001b[1;32m    802\u001b[0m     }\n\u001b[1;32m    804\u001b[0m field_info, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_field_info(name, type_, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config)\n\u001b[0;32m--> 806\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_validators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_validators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/fields.py:434\u001b[0m, in \u001b[0;36mModelField.__init__\u001b[0;34m(self, name, type_, class_validators, model_config, default, default_factory, required, final, alias, field_info)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m SHAPE_SINGLETON\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mprepare_field(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 434\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/fields.py:555\u001b[0m, in \u001b[0;36mModelField.prepare\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;129;01mis\u001b[39;00m Undefined \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 555\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopulate_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/fields.py:829\u001b[0m, in \u001b[0;36mModelField.populate_validators\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msub_fields \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m SHAPE_GENERIC:\n\u001b[1;32m    826\u001b[0m     get_validators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__get_validators__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    827\u001b[0m     v_funcs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    828\u001b[0m         \u001b[38;5;241m*\u001b[39m[v\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m class_validators_ \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item \u001b[38;5;129;01mand\u001b[39;00m v\u001b[38;5;241m.\u001b[39mpre],\n\u001b[0;32m--> 829\u001b[0m         \u001b[38;5;241m*\u001b[39m(get_validators() \u001b[38;5;28;01mif\u001b[39;00m get_validators \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfind_validators\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[1;32m    830\u001b[0m         \u001b[38;5;241m*\u001b[39m[v\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m class_validators_ \u001b[38;5;28;01mif\u001b[39;00m v\u001b[38;5;241m.\u001b[39meach_item \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m v\u001b[38;5;241m.\u001b[39mpre],\n\u001b[1;32m    831\u001b[0m     )\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidators \u001b[38;5;241m=\u001b[39m prep_validators(v_funcs)\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_validators \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pydantic/v1/validators.py:765\u001b[0m, in \u001b[0;36mfind_validators\u001b[0;34m(type_, config)\u001b[0m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m make_arbitrary_type_validator(type_)\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno validator found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, see `arbitrary_types_allowed` in Config\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: no validator found for <class '__main__.Actor'>, see `arbitrary_types_allowed` in Config"
     ]
    }
   ],
   "source": [
    "extractor = create_extraction_chain_pydantic(pydantic_schema=Actor, llm=model)\n",
    "extracted = extractor.run(dataset[1][\"text\"])\n",
    "extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8451c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(extracted[0].Actor == inp[1][\"Actor\"]) & (extracted[0].Film == inp[1][\"Film\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b03de4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
